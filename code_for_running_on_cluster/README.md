# Code for running an array job on a cluster

## General
In this folder you can find the code you need to run a batch of simulations as an array job on a Grid Engine computer cluster (works on the Open Grid Scheduler batch system on Scientific Linux 7 at least). The example allows you to create an array job on a cluster which runs the same simulation (2 independent runs of a single learner learning from a single speaker for 30 observations) but looping through each of the possible speaker lexicons (for a lexicon with 3 meanings and 3 signals in this case; 343 possible lexicons in total).

## Usage Instructions
In order to run this array job on a cluster, upload the files in this folder *and* all the modules in the folder [python_code/modules](https://github.com/marieke-woensdregt/model_coevolution_language_mindreading/tree/master/python_code/modules), and submit the job with the command `qsub eddie_run_learner_speaker_diff_lexicons_p_prior_egoc_sp_literal_P1_a1_lr_perspective-taking_a1_lr_sp_hyp_literal_30_C_2_R.sh`
The code in this folder is meant for doing a quick test run with only 30 observations per learner and only 2 independent simulation runs. You can change these parameters in the parameter settings block at the top of the python script [run_learner_speaker_diff_lexicons_p_prior_egoc_sp_literal_P1_a1_lr_perspective-taking_a1_lr_sp_hyp_literal_30_C_2_R.py](https://github.com/marieke-woensdregt/model_coevolution_language_mindreading/blob/master/code_for_running_on_cluster/run_learner_speaker_diff_lexicons_p_prior_egoc_sp_literal_P1_a1_lr_perspective-taking_a1_lr_sp_hyp_literal_30_C_2_R.py). (e.g. change `n_contexts = 30` to `n_contexts = 300` and `n_runs = 2` to `n_runs = 200`). 
**NOTE** if you want to run a longer simulation than the one in this example, you'll also have to change the maximum number of hours allowed for the simulation in the `.sh` file by changing the parameter `#$ -l h_rt=02:00:00` to e.g. `#$ -l h_rt=15:00:00`. A simulation of a literal learner learning from a literal speaker (as in this example code) with 300 observations per learner and 200 separate runs should take about 7 hours to run, but make sure you leave a reasonable amount of buffer in case it takes a bit longer. For some simulations you might also have to increase the memory limit (currently set to 1.5 GB) by changing the line `#$ -l h_vmem=1.5G` in the `.sh` script.


## Navigating the code
Throughout these modules I used a mixture of object-oriented programming and regular functions, and explained how each function, class or method works using docstrings and comments. I also used long and intelligible variable and function names, which should hopefully make the code relatively easy to read.

# Instructions:

In order to run this array job on a cluster, upload the files in this folder *and* all the modules in the folder [python_code](https://github.com/marieke-woensdregt/model_coevolution_language_mindreading/tree/master/python_code), and submit the job with the command `qsub eddie_run_learner_speaker_diff_lexicons_p_prior_egoc_sp_literal_P1_a1_lr_perspective-taking_a1_lr_sp_hyp_literal_30_C_2_R.sh`
The code in this folder is meant for doing a quick test run with only 30 observations per learner and only 2 independent simulation runs. You can change these parameters in the parameter settings block at the top of the python script `run_learner_speaker_diff_lexicons_p_prior_egoc_sp_literal_P1_a1_lr_perspective-taking_a1_lr_sp_hyp_literal_30_C_2_R.py`. (e.g. change `n_contexts = 30` to `n_contexts = 300` and `n_runs = 2` to `n_runs = 200`). 
**NOTE** if you want to run a longer simulation than the one in this example, you'll also have to change the maximum number of hours allowed for the simulation in the `.sh` file by changing the parameter `#$ -l h_rt=02:00:00` to e.g. `#$ -l h_rt=15:00:00`. A simulation of a literal learner learning from a literal speaker (as in this example code) with 300 observations per learner and 200 separate runs should take about 7 hours to run, but make sure you leave a reasonable amount of buffer in case it takes a bit longer. For some simulations you might also have to increase the memory limit (currently set to 0.75 GB) by changing the line `#$ -l h_vmem=0.75G` in the `.sh` script.

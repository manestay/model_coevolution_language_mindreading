# COPY THIS FILE AND MODIFY FROM THERE
# comments above entries indicate possible choices (or a comment on values)

[paths]
root_path = /nlp/data/bryanli/projects/model_coevolution_language_mindreading/results
pickle_file_directory = %(root_path)s/pickles/
plot_file_directory = %(root_path)s/plots/
run_type_dir = Bilingualism

[lexicon]
n_meanings = 2
n_signals = 2

[context]
# random , only_helpful , optimal
context_generation = optimal
# continuous , absolute
context_type = continuous
context_size = 1
sal_alpha = 1.
error = 0.05
extra_error = True

[population]
pop_size = 10
# p_distinction , no_p_distinction
agent_type = no_p_distinction
# literal , perspective-taking, prag
pragmatic_level = prag
optimality_alpha = 3.0
# sng_teacher ,  multi_teacher
teacher_type = sng_teacher

[hypothesis]
perspective_hyps = 0 1
# all , all_with_full_s_space , only optimal
which_lexicon_hyps = all

[pop_makeup]
perspectives = 0 1
perspective_probs = 0. 1.
learning_types = map sample
learning_type_probs = 0. 1.
# perspective_unknown, lexicon_unknown or both_unknown
learner_type = both_unknown
learner_perspective = 0
# neutral, egocentric, same_as_lexicon or zero_order_tom
perspective_prior_type = egocentric
perspective_prior_strength = 0.9
# neutral, ambiguous_fixed, half_ambiguous_fixed, expressivity_bias or compressibility_bias
lexicon_prior_type = neutral
# small c means strong prior, large c means weak prior
lexicon_prior_constant = 0.0

[learner]
n_utterances = 1
n_contexts = 120
# random , random_equal , same_first , same_first_equal , opp_first , opp_first_equal
speaker_order_type = random
first_input_stage_ratio = 0.5

[simulation]
# dyadic , population_diff_pop , population_same_pop population_same_pop_dist_learner iter
run_type = iter
# lex_only, lex_n_context, lex_n_p or prag
communication_type = prag
# "comp_n_prod" or "comp_only"
ca_measure_type = comp_only
# for communicative accuracy
n_interactions = 6
# ca_with_parent , none or p_taking
selection_type = ca_with_parent
# 0 means neutral setting, 1 means full weighting
selection_weighting = 1.0
# chain , whole_pop
turnover_type = whole_pop
n_iterations = 200
report_every_i = 1
cut_off_point = 5
n_runs = 2
report_every_r = 1

# everything or minimal
recording = minimal
# all_hyps or lex_hyps_only
which_hyps_on_graph = all_hyps
# mi , ca
lex_measure = ca
posterior_threshold = 0.95
decoupling = True
multithread = True
